\chapter{Обзор подходов к сравнению методов сжатия облаков точек}

% что такое лузлес
% что такое лосси

В общем случае, информация может быть сжата, если она является избыточной.
Сжатие без потерь основано на уменьшения избыточности информации. В сжатии с
потерями вводится новое понятие - нерелевантная информация, то есть такая
информация, которая слабо влияет на восприятие изображения человеком. Сжатие с
потерями, таким образом, основано не только на уменьшении избыточности, но и на
определении нерелевантной информации и уменьшении количества подобной
информации\cite[265]{DataCompression}.

В случае, когда визуальная информация предназначена прежде всего для восприятия
человеком, единственной корректной метрикой визуального качества изображения
является субъективная оценка некоторой отобранной группой
людей\cite{SSIMArticle}. Данный подход, однако, не является машинным и,
следовательно, не подлежит автоматизации. Для решения данной проблемы были
разработаны метрики, помогающие автоматически предсказать \textit{воспринимаемое
качество (perceived quality)} изображения. К подобным метрикам относится метрики
качества изображения SSIM и VIF(Visual Image Fidelity).

\section{Подходы к оценке качества сжатия изображений}

% мб сабсекции?
% перцепчуал метрики
% не перцепчуал метрики

Потребность в оценке качества сжатия визуальной информации возникла после
изобретения методов сжатия подобной информации. Многие из качественных метрик
сжатия 3Д-данных, были изначально разработаны для оценки качества сжатия обычных
изображений.

Введем понятие реконструированного изображения. Пусть оригинальное изображение
$A$ было закодировано в формате $F_{1}$. Закодируем оригинальное изображение с
использованием алгоритма сжатия и получим сжатое изображение $B$, закодированное
в формате $F_{2}$. Теперь произведем декомпрессию изображения $B$ и закодируем
его с помощью формата $F_{1}$. Полученное изображение $C$ в формате $F_{1}$ -
реконструированное изображение.

Метрики качества для медиа могут быть классифицированы согласно тому, с чем
сравнивается реконструированное изображение\cite{SSIMArticle}:

\begin{itemize}
    \item С оригинальным, неискаженным изображением
    \item С набором признаков, извлеченных из оригинального изображения
    \item С самим собой (!!!)
\end{itemize}

Другая классификация предполагает разделение метрик по признаку того, на чём они
основаны\cite[6]{FullReferenceIQMetrics}:

\begin{itemize}
    \item Математически-обоснованные метрики, учитывающие лишь интенсивность
    искажения. К подобным метрикам относятся среднеквадратичная ошибка (MSE) и пиковое
    отношение сигнал-шум (PSNR)
    \item Низкоуровневые метрики, которые учитывают видимость искажений, как,
    например функции чувствительности контраста (CSF)
    \item Высокоуровневые метрики, которые основаны на гипотезе о том, что
    человеческое зрение адаптировано к извлечению структурной информации из
    изображения. К подобным метрикам относится индекс структурной похожести
    (SSIM) и визуальная точность изображения (VIF)
\end{itemize}

\subsubsection{Математически-обоснованные метрики качества}

Одной из стандартных метрик качества сжатия изображений является пиковое
отношение сигнал-шум (Peak Signal to Noise Ratio - далее PSNR). Данная метрика
достаточно проста для вычисления, однако она имеет лишь ограниченное,
приблизительное отношение к ошибкам, которые воспринимает человеческий глаз.
Иными словами, большее значение PSNR означает меньшее расхождение между
оригинальным и сжатым изображением, но не гарантирует, что зрителям понравится
реконструированное изображение\cite[279]{DataCompression}.

Обозначим пиксели исходного изображения как $P_{i}$, а пиксели
реконструированного изображения как $Q_{i}$ $\left(\text{где} \ 0 \le i \le
n\right)$. Для начала определим понятие среднеквадратичной ошибки (Mean Squared
Error - далее MSE) между двумя изображениями как

\begin{equation} \label{eq:img_mse}
    MSE = \frac{1}{n} \sum_{i=1}^{n}\left(P_{i} - Q_{i}\right)^2
\end{equation}

Иными словами, среднеквадратичная ошибка для изображений является суммой
квадратов ошибок для каждого из пикселей. Тогда метрика PSNR может быть
определена как

\begin{equation} \label{eq:img_psnr}
    \text{PSNR} = 10\log_{10} \frac{\max_{i}\left|P_{i}\right|^{2}}{MSE}
\end{equation}

При этом $\max_{i}\left|P_{i}\right|$ - пиковое значение сигнала. Для
чёрно-белого изображения пиковым значением является 1, для изображения в
оттенках серого при глубине 8 бит на пиксель данное значение равно 255. Так как
используется логарифм отношения, результирующее значение измеряется в децибелах.

Метрика PSNR имеет значение лишь в сравнении c показателями данной метрики для
того же (или схожего) кодека и тех же входных данных при отличных входных
параметрах\cite{HuynhThu2008}. Несмотря на это, данная метрика продолжает
использоваться исследователями для сравнения качества работы существующих
кодеков с предлагаемыми ими решениями\cite{NetflixVMAFMedium}.

Другой похожей метрикой является отношение сигнала к шуму (Signal to Noise Ratio
- далее SNR). В данном случае, рассматривается не пиковое значение сигнала, а
среднеквадратичное.

\begin{equation} \label{eq:img_snr}
    \text{SNR} = 10\log_{10} \frac{\frac{1}{n}\sum_{i=1}^{n} P_{i}^{2}}{MSE}
\end{equation}

Значение отношения сигнала к шуму квантования (Signal to Quantization Noise
Ratio - далее SQNR) представляет собой меру влияния квантования на качество
сигнала. Данную метрику можно определить как отношение мощности сигнала к
разнице между сигналом после квантования и оригинальным значением сигнала.

\begin{equation} \label{eq:img_sqnr}
    \text{SQNR} = 10\log_{10} \frac{\text{signal power}}{\text{quantization error}}
\end{equation}

\subsubsection{Высокоуровневые метрики качества}

Математически-обоснованные метрики основаны на предположении, что уменьшение
воспринимаемого качества изображения напрямую связано с величиной шума. Так,
например, MSE даёт объективную оценку мощности (?) шума, однако два зашумленных
изображения с одинаковым значением MSE могут ошибки разного рода, некоторые из
которых являются более заметными чем другие. Для решения данной проблемы были
предложены высокоуровневые метрики качества изображений.

Здесь можно стырить иллюстрацию с лодками из\cite{SSIMArticle}.

% ниже chatgpt

Рассмотрим индекс структурной похожести (SSIM), данная метрика была предложена в
качестве способа предсказания воспринимаемого качества изображения. Она
представляет собой более точную и соответствующую человеческому восприятию
метрику для оценки качества сжатия изображений, поскольку учитывает структурные
и текстурные аспекты изображения, в то время как MSE и PSNR ориентированы на
разницу в значениях пикселей без учета визуальных особенностей.

% ниже chatgpt

\paragraph{SSIM (Structural Similarity Index)} вычисляется сравнением трех основных аспектов
изображений: яркости (luminance), контрастности (contrast) и структуры
(structure). Вот формула для вычисления SSIM:

\begin{equation} \label{eq:img_ssim}
    \text{SSIM}\left(x, y\right) = \frac{
        \left(2\mu_{x}\mu_{y} + c_{1}\right)\left(2\sigma_{xy} + c_{2}\right)
    }{
        \left(\mu_{x}^{2} + \mu_{y}^2 + c_{1}\right)\left(\sigma_{x}^{2} + \sigma_{y}^{2} + c_{2}\right)
    }
\end{equation}

\noindent где:

\begin{itemize}
    \item $x$ и $y$ - сравниваемые изображения
    \item $\mu_{x}$ и $\mu_{y}$​ - средние значения пикселей изображений $x$ и $y$
    \item $\sigma_{x}^{2}$ и $\sigma_{y}^{2}$ - дисперсии значений пикселей изображений $x$ и $y$
    \item $\sigma_{xy}$ - ковариация между значениями пикселей изображений $x$ и $y$
    \item $c_{1}$ и $c_{2}$ - константы для обеспечения устойчивости деления
\end{itemize}

% ниже chatgpt

Этот индекс обычно принимает значения от $-1$ до $1$, где $1$ указывает на
идеальное сходство между изображениями, а значения ближе к $-1$ указывают на
более сильные различия.

% ниже chatgpt

SSIM сравнивает локальные окрестности пикселей изображений, а не их абсолютные
значения. Он учитывает не только яркость и контрастность, но и структуру
изображения, что делает его более подходящим для оценки качества изображений с
точки зрения человеческого восприятия

% ниже chatgpt

\paragraph{VIF (Visual Information Fidelity)}. VIF обеспечивает более точную
оценку качества сжатия, так как учитывает не только структурные аспекты
изображения, но и сложные визуальные особенности, такие как текстуры, края и
детали. Это делает VIF более подходящей метрикой для оценки реального восприятия
качества изображения человеком.

% ниже chatgpt

Вычисление Visual Information Fidelity (VIF) включает несколько этапов,
включающих оценку сходства между двумя изображениями с учетом их визуальной
информации. Вот общий алгоритм вычисления VIF:

\begin{itemize}
    \item Разбиение изображений на блоки: Сначала изображения разбиваются на
    небольшие блоки пикселей. Обычно используются квадратные блоки определенного
    размера.
    \item Вычисление локальных статистических параметров: Для каждого блока
    изображения вычисляются локальные статистические параметры, такие как
    среднее значение, дисперсия и ковариация пикселей.
    \item Вычисление локальных масштабных параметров: Для каждого блока
    изображения также вычисляются локальные масштабные параметры, которые
    оценивают структурную информацию в блоке.
    \item Вычисление глобальных статистических параметров: Глобальные
    статистические параметры вычисляются на основе суммирования или усреднения
    локальных параметров по всем блокам изображений.
    \item Вычисление VIF: Затем производится расчет VIF, используя локальные
    и глобальные параметры. В общем, VIF представляет собой взвешенную сумму
    сходства между локальными статистическими параметрами двух изображений.
    \item Нормализация VIF: Иногда VIF может быть нормализован для получения
    значения в диапазоне от 0 до 1, где 1 указывает на идеальное сходство между
    изображениями.
\end{itemize}

% ниже chatgpt

Это общий алгоритм, и реальная реализация VIF может включать дополнительные
детали и оптимизации. Однако основная идея заключается в том, чтобы учитывать
как локальные, так и глобальные статистические параметры изображений для оценки
их визуального сходства.

% ниже chatgpt

В целом, VIF обеспечивает более глубокую и точную оценку качества сжатия
изображений, учитывая разнообразные визуальные особенности и взаимосвязи между
блоками изображения, что делает его ценным инструментом при сравнении различных
методов сжатия изображений.

% \paragraph{Netflix VMAF}

\section{Подходы к оценке качества сжатия облаков точек}

% Ввести в область и рассказать про метрики фото, видео

% Классифицировать метрики

% Рассказать как их адаптировать для пойнт клаудов

Идея многих подходов к оценке качества сжатия облаков точек взята из более
глубоко проработанной области оценки качества изображений и видео. Облака точек,
однако представляют собой гораздо более сложный объект, что влияет не только на
то, какие стандартные математически-обоснованные качественные метрики можно к
ним применить, но и на сам процесс вычисления данных метрик. Рассмотрим
терминологию, связанную с наличием потерь при сжатии облаков
точек\cite{CallForProposalV2}:

\begin{itemize}
    \item Геометрическая структура с потерями - декодированная сжатая
    геометрическая структура не обязательно численно совпадает с изначальной
    геометрической структурой. Количество точек в декодированном облаке также
    может не совпадать с количеством точек в изначальном облаке
    \item Геометрическая структура без потерь - декодированная сжатая
    геометрическая структура численно совпадает с изначальной геометрической
    структурой в отношении значений $\left(x, y, z\right)$. Количество точек в
    декодированном облаке также совпадает с количеством точек в изначальном
    облаке
    \item Атрибуты с потерями - декодированные сжатые атрибуты не обязательно
    численно совпадают с изначальными атрибутами
    \item Атрибуты без потерь - декодированные сжатые атрибуты полностью
    численно совпадают с изначальными атрибутами
\end{itemize}

Очевидно, что метрики качества релевантны только для методов сжатия
геометрической структуры с потерями и методов сжатия атрибутов с потерями.
Рассмотрим, как некоторые из вышеупомянутых метрик можно адаптировать для оценки
качества сжатия облаков точек.

% мб вот эту матемагию для 2-3 части оставить?
% а здесь описать то же самое словами

Искажение геометрической структуры можно оценить, вычислив среднеквадратичную
ошибку искажения. Для этого необходимо определить, что собой представляет ошибка
для единичной точки.

Пусть $X, Y$ - облака точек, тогда $x_{0}, x_{1}, \dots, x_{n}$ - точки облака
$X$, где $n$ - количество точек в облаке $X$, соответственно, $y_{0}, y_{1},
\dots, y_{m}$ - точки реконструированного облака $Y$, где $m$ - количество точек
в облаке $Y$. Каждая из точек представляет собой вектор, принадлежащий
векторному пространству $\mathbb{R}^{3}$. Составим облако $Y'$ состоящее из $n$
точек по следующему алгоритму: для каждой точки $x_{i} \in X$ найдем точку
$y_{j} \in Y$, наиболее близкую к $x_{i}$, добавим в облако $Y'$ точку $y'_{i} =
y_{j}$. В итоге, количество точек в облаках $X$ и $Y'$ будет окажется
одинаковым, при этом для любого $i \in \left[1, n\right]$ $y'_{i}$ будет
ближайшим соседом точки $x_{i}$ в облаке $Y'$.

Таким образом, ошибка для единичной точки $x_{i}$ представляет собой расстояние
от данной точки до $y'_{i}$. Определим среднеквадратичную ошибку как

\begin{equation} \label{eq:cloud_mse}
    \text{MSE} = \frac{1}{n} \sum_{i = 0}^{n} \left( x_{i} - y'_{i} \right)^{2}
\end{equation}

Примем за пиковое значения сигнала максимальное расстояние от точки до её
ближайшего соседа внутри облака $X$. Тогда пиковое отношение сигнал-шум можно
определить как

\begin{equation} \label{eq:cloud_psnr}
    \text{PSNR} = 10\log_{10} \frac{\left(\text{max distance}\right)^{2}}{\text{MSE}}
\end{equation}

% тут ссылка на китайцев??

Высокоуровневые метрики для оценки качества изображений также возможно
адаптировать для оценки облаков точек. Для этого необходимо произвести рендеринг
облака и получить одно или несколько обычных изображений данного облака. Далее,
по полученным изображениям возможно рассчитать высокоуровневые метрики качества,
такие как SSIM и VIF. Указанный подход целесообразен в случае, когда данные
предназначены для восприятия человеком, например, при использовании облака для
рендеринга или в системах расширенной реальности.

\section{Системы оценки качества сжатия облаков точек}

\paragraph{mpeg-pcc-dmetric}

\paragraph{GeoCNNv1 geo\_dist}

\paragraph{PCCArena}




\chapter{Обоснование выбора технологий и средств разработки}



\chapter{Система подсчёта метрик}




\chapter{Результаты работы}



% \chapter{Название главы}
%   \section{Названия секции}
%     \subsubsection{Название подсекции}
%       \paragraph{Название параграфа}
%         \subparagraph{Название подпараграфа}
%           \lipsum[2]\cite{BibExampleRU}
%           \begin{center}
%             \begin{xltabular}{\linewidth}{|l|X|}
%               \caption{Long table caption.\label{long}}                                                                                                    \\
%               \hline
%               Столбик1  & Столбик2    \\
%               \hline
%               слово     & Слово       \\
%               \hline
%             \end{xltabular}
%           \end{center}


% \chapter{Название главы}
%   \section{Названия секции}
%     \subsubsection{Название подсекции}
%       \paragraph{Название Параграфа}
%         \lipsum[2]\cite{BibExampleRU}
%         Как видно на \refImg{img:test} или на \refAppendix{appendix:example}
%         \fig[Длинное название картинки из примера][0.5][img:test]{assets/example.drawio.png}

%         \begin{center}
%           \begin{xltabular}{\linewidth}{|l|X|}
%             \caption{Long table caption.\label{long}}                                                                                                    \\
%             \hline
%             Столбик1  & Столбик2    \\
%             \hline
%             слово     & Слово       \\
%             \hline
%           \end{xltabular}
%         \end{center}

%         \begin{lstlisting}[caption={Название листинга}]
% begin
%   print('Hellow world!')
% end
%         \end{lstlisting}

%         \begin{itemize}
%           \item item1
%           \item item2
%         \end{itemize}

%         \begin{enumerate}
%           \item item1
%           \item item2
%         \end{enumerate}
